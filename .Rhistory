sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species)
testset_knn <- testset %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
# transforming character factor into numerics
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species)
# calculating k
k <- round(sqrt(dim(trainset_knn)[1]))
if (k %% 2 == 1) {
k = k} else {
k = k + 1}
# predicting species via kNN
predictions_kNN <- knn(train = trainset_knn,
test = testset_knn,
cl = trainset_species,
k = k)
# storing accuracy in accuracy_kNN
accuracy_kNN <- accuracy_testing(vector_predictions = predictions_kNN,
vector_trueclasses = testset_species)
accuracy_kNN
trainset_knn <- trainset  %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
# transforming character factor into numerics
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species)
testset_knn <- testset %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
# transforming character factor into numerics
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species)
# calculating k
k <- round(sqrt(dim(trainset_knn)[1]))
if (k %% 2 == 1) {
k = k} else {
k = k + 1}
# predicting species via kNN
predictions_kNN <- knn(train = trainset_knn,
test = testset_knn,
cl = trainset_species,
k = k)
# storing accuracy in accuracy_kNN
accuracy_kNN <- accuracy_testing(vector_predictions = predictions_kNN,
vector_trueclasses = testset_species)
accuracy_kNN
logit_model1 <- multinom(species ~ island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g + sex + year,
data = trainset)
summary(logit_model1)
testset_logistic <- testset %>%
select(- species)
?predict
predict(logit_model1, testset_logistic)
predict(logit_model1, testset_logistic, type = "probs")
predict(logit_model1, testset_logistic)
predictions_logit <- predict(logit_model1, testset_logistic)
accuracy_logistic <- accuracy_testing(vector_predictions = predictions_logit,
vector_trueclasses = testset_species)
accuracy_logistic
accuracy_logistic
?randomForest
# defining formula for random forest algorithm
rf.formula <- as.formula("species ~ island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g + sex + year")
anova(rf.formula)
?anova
library(car)
Anova(logit_model1)
lm(species ~ island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g + sex + year, data = penguins_data)
summary(lm(species ~ island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g + sex + year, data = penguins_data))
testset_randomforest <- testset %>%
select(- species)
rf.model <- randomForest(rf.formula,
data = trainset)
rf.model
predictions_randomforest <- predict(rf.model,
newdata = testset_randomforest)
accuracy_randomforest <- accuracy_testing(vector_predictions = predictions_randomforest,
vector_trueclasses = testset_species)
accuracy_randomforest
accuracy_logistic
accuracy_randomforest
# predicting species via kNN
predictions_kNN <- knn(train = trainset,
test = testset_logistic,
cl = trainset_species,
k = k)
trainset_x <- trainset %>% select(-species)
# predicting species via kNN
predictions_kNN <- knn(train = trainset_x,
test = testset_logistic,
cl = trainset_species,
k = k)
# specifically manipulating data sets for kNN algorithm
trainset_knn <- trainset  %>%
mutate(
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species) # omitting species from set
testset_knn <- testset %>%
mutate(
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species) # omitting species from set
# calculating k
k <- round(sqrt(dim(trainset_knn)[1]))
if (k %% 2 == 1) {
k = k} else {
k = k + 1}
# predicting species via kNN
predictions_kNN <- knn(train = trainset_knn,
test = testset_knn,
cl = trainset_species,
k = k)
# storing accuracy in accuracy_kNN
accuracy_kNN <- accuracy_testing(vector_predictions = predictions_kNN,
vector_trueclasses = testset_species)
accuracy_kNN
testset_knn
# specifically manipulating data sets for kNN algorithm
trainset_knn <- trainset  %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
# transforming character factor into numerics
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species) # omitting species from set
testset_knn <- testset %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
# transforming character factor into numerics
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species) # omitting species from set
# calculating k
k <- round(sqrt(dim(trainset_knn)[1]))
if (k %% 2 == 1) {
k = k} else {
k = k + 1}
# predicting species via kNN
predictions_kNN <- knn(train = trainset_knn,
test = testset_knn,
cl = trainset_species,
k = k)
# storing accuracy in accuracy_kNN
accuracy_kNN <- accuracy_testing(vector_predictions = predictions_kNN,
vector_trueclasses = testset_species)
accuracy_kNN
rf.model
summary(rf.model)
summary(rf.model)$importance
summary(rf.model)[3]
install.packages(varImp)
install.packages("varImp")
library(varImp)
?importance
importance(rf.model)
importance(rf.model, type = 1)
importance(rf.model)
rm(GCtorture)
testset_logistic
# training logistic regression model (logit model)
logit_model1 <- multinom(species ~ island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g,
data = trainset)
# computing predictions using logit model
predictions_logit <- predict(logit_model1, testset_logistic)
# computing and storing accuracy
accuracy_logistic <- accuracy_testing(vector_predictions = predictions_logit,
vector_trueclasses = testset_species)
accuracy_logistic
# computing importance of features
importance(rf.model)
library(effects)
plot(effect("bill_length_mm", logit_model1))
# training logistic regression model (logit model)
logit_model1 <- multinom(rf.formula,
data = trainset)
# computing predictions using logit model
predictions_logit <- predict(logit_model1, testset_logistic)
# computing and storing accuracy
accuracy_logistic <- accuracy_testing(vector_predictions = predictions_logit,
vector_trueclasses = testset_species)
accuracy_logistic
# Visualising the effect of variables on probability of classification
plot(effect("island", logit_model1))
penguins_data$species[penguins_data$island]
penguins_data$species[penguins_data$island == "Adelie"]
View(penguins_data)
?effect
# computing importance of features
importance(rf.model)
importance(rf.model, type = 1)
# computing importance of features
importance(rf.model)
# Results
results_accuracy <- data.frame(algorithm = c("kNN", "logistic regression", "random forest"),
accuracy = c(accuracy_kNN, accuracy_logistic, accuracy_randomforest))
results_accuracy
table(testset_species , predictions_logit)
install.packages("caret")
library(caret)
confusionMatrix(data = ,)
confusionMatrix(data = predictions_logit,
reference = testset_species)
# model assessment
confusionMatrix(data = predictions_kNN, reference = testset_species)
# calculating accuracy
# model assessment
confusionMatrix(data = predictions_randomforest, reference = testset_species)
# Results accuracy
results_accuracy <- data.frame(algorithm = c("kNN", "logistic regression", "random forest"),
accuracy = c(accuracy_testing(vector_predictions = predictions_kNN,
vector_trueclasses = testset_species),
accuracy_testing(vector_predictions = predictions_logit,
vector_trueclasses = testset_species),
accuracy_testing(vector_predictions = predictions_randomforest,
vector_trueclasses = testset_species)))
results_accuracy
# NOTE: path needs to be altered if function is run!
# exporting data frame as csv.
write.csv(results_accuracy,
"/Users/nicoherrig/Desktop/Data Science Projects/Penguin-classification-algorithm/results_accuracy.csv",
row.names = FALSE)
penguins
?penguins
?class
?kNN
?knn
penguins_data
install.packages("stats19")
library(stats19)
x <- get_stats19(year = 2020)
View(x)
# First script to run - includes kNN-algorithm to classify sex of penguins
# install.packages("palmerpenguins")
library(palmerpenguins)
library(tidyverse)
library(class)
source("functions.R")
data <- penguins %>%
# dropping observations where predictive features are missing
drop_na(bill_length_mm, bill_depth_mm, flipper_length_mm)
# Classification of sex with k-nearest neighbour classification algorithm
# separating training set and testig set with 80/20 separation
# sampling for train set observations (80% of data)
obs_train <- sample(x = seq(1, nrow(data)),
size = nrow(data)*0.8)
# sampling for test set observations (20% of data)
obs_test <- seq(1, nrow(data))[- obs_train]
# Normalization function
normalizer <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
# manipulating data for kNN algorithm testing
data_knn <- data %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
# transforming character factor into numerics
species = as.numeric(species),
island = as.numeric(island),
year = as.factor(year)) # year into factor
# observations where sex is latent
latent_obs_sex <- which(is.na(data$sex))
data_sex_latent <- data[latent_obs_sex,] %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
species = as.numeric(species),
island = as.numeric(island))
data_sex_available <- data[-latent_obs_sex,] %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
species = as.numeric(species),
island = as.numeric(island))
# extracting true classification values from non-latent data set
true_class <- data_sex_available$sex
# omitting column sex from data sets
data_sex_latent <- data_sex_latent %>%
select(- sex)
data_sex_available <- data_sex_available %>%
select(- sex)
# calculating k
initial_k <- round(sqrt(dim(data_sex_available)[1]))
if (initial_k %% 2 == 1) {
initial_k = initial_k} else {
initial_k = initial_k + 1} # +1 if k is even, as we want odd k
# predictions
predictions_sex_latent <- knn(train = data_sex_available,
test = data_sex_latent,
cl = true_class,
k = initial_k)
# implementing predicted values into initial data set
data$sex[latent_obs_sex] <- predictions_sex_latent
# NOTE: path needs to be altered if function is run!
# exporting data frame as csv.
write.csv(data,
"/Users/nicoherrig/Desktop/Data Science Projects/Penguin-classification-algorithm/penguins_sex.csv",
row.names = FALSE)
# Main script
# Second script to run
# Compares three classification algorithms:
# -> kNN, logistic Regression, Random Forest
library(tidyverse)
library(ggplot2)
library(class)
library(randomForest)
library(nnet)
library(car)
library(effects)
# source file for functions
source("functions.R")
# reading in cleaned and completed data set
penguins_data <- read_csv("penguins_sex.csv") %>%
mutate(species = as.factor(species),
island = as.factor(island),
sex = as.factor(sex),
year = as.factor(year))
# Basic Exploratory data analysis (Overview about data)
# Distribution of observations by species
penguins_data %>%
ggplot(aes(y = species, fill = species))+
geom_bar()+
geom_text(aes(label = ..count..),
stat = "count",
hjust=1.5,
colour = "black",
size = 5)+
theme(legend.position = "none")
penguins_data %>%
ggplot(aes(x = bill_length_mm, fill = species))+
geom_histogram(alpha = 0.5)+
theme(legend.position = "top",
plot.title = element_text(hjust = 0.5))+
ggtitle("Bill Length")
penguins_data %>%
ggplot(aes(x = bill_depth_mm, fill = species))+
geom_histogram(alpha = 0.5)+
theme(legend.position = "top",
plot.title = element_text(hjust = 0.5))+
ggtitle("Bill Depth")
penguins_data %>%
ggplot(aes(x = body_mass_g, fill = species))+
geom_histogram(alpha = 0.5)+
theme(legend.position = "top",
plot.title = element_text(hjust = 0.5))+
ggtitle("Body Mass")
penguins_data %>%
filter(species == "Adelie") %>%
group_by(sex) %>%
summarise(avg_bill_length = mean(bill_length_mm, na.rm = TRUE),
avg_bill_depth = mean(bill_depth_mm, na.rm = TRUE),
avg_flipper_lengt = mean(flipper_length_mm, na.rm = TRUE),
avg_weight_g = mean(body_mass_g, na.rm = TRUE))
penguins_data %>%
filter(species == "Gentoo") %>%
group_by(sex) %>%
summarise(avg_bill_length = mean(bill_length_mm, na.rm = TRUE),
avg_bill_depth = mean(bill_depth_mm, na.rm = TRUE),
avg_flipper_lengt = mean(flipper_length_mm, na.rm = TRUE),
avg_weight_g = mean(body_mass_g, na.rm = TRUE))
penguins_data %>%
filter(species == "Chinstrap") %>%
group_by(sex) %>%
summarise(avg_bill_length = mean(bill_length_mm, na.rm = TRUE),
avg_bill_depth = mean(bill_depth_mm, na.rm = TRUE),
avg_flipper_lengt = mean(flipper_length_mm, na.rm = TRUE),
avg_weight_g = mean(body_mass_g, na.rm = TRUE))
penguins_data %>%
ggplot(aes(x = bill_length_mm, y = body_mass_g, colour = species))+
geom_point()+
ggtitle("Cluster 1")+
theme(plot.title = element_text(hjust = 0.5))
penguins_data %>%
ggplot(aes(x = bill_depth_mm, y = body_mass_g, colour = species))+
geom_point()+
ggtitle("Cluster 2")+
theme(plot.title = element_text(hjust = 0.5))
penguins_data %>%
ggplot(aes(x = flipper_length_mm, y = body_mass_g, colour = species))+
geom_point()+
ggtitle("Cluster 3")+
theme(plot.title = element_text(hjust = 0.5))
# generate general trainset and testset
# sets are used for all algorithms but are eventually further modified for each
# algorithm individually
set.seed(0911) # setting seed for reproducibility
sets <- set_generator(data = penguins_data) # storage variable for both sets
trainset <- as.data.frame(sets[1])%>%
rename(species = trainset.species,
bill_length_mm = trainset.bill_length_mm,
bill_depth_mm = trainset.bill_depth_mm,
flipper_length_mm = trainset.flipper_length_mm,
body_mass_g = trainset.body_mass_g,
sex = trainset.sex,
island = trainset.island,
year = trainset.year)
testset <- as.data.frame(sets[2])%>%
rename(species = testset.species,
bill_length_mm = testset.bill_length_mm,
bill_depth_mm = testset.bill_depth_mm,
flipper_length_mm = testset.flipper_length_mm,
body_mass_g = testset.body_mass_g,
sex = testset.sex,
island = testset.island,
year = testset.year)
rm(sets) #removing storage variable for both sets
# extracting target columns
trainset_species <- trainset$species
testset_species <- testset$species
# CLASSIFICATION ALGORITHMS
# 1. KNN
# specifically manipulating data sets for kNN algorithm
trainset_knn <- trainset  %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
# transforming character factor into numerics
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species) # omitting species from set
testset_knn <- testset %>%
mutate(bill_length_mm = normalizer(bill_length_mm),
bill_depth_mm = normalizer(bill_depth_mm),
flipper_length_mm = normalizer(flipper_length_mm),
body_mass_g = normalizer(body_mass_g),
# transforming character factor into numerics
sex = as.numeric(sex),
island = as.numeric(island)) %>%
select(- species) # omitting species from set
# calculating k
k <- round(sqrt(dim(trainset_knn)[1]))
if (k %% 2 == 1) {
k = k} else {
k = k + 1}
# predicting species via kNN
predictions_kNN <- knn(train = trainset_knn,
test = testset_knn,
cl = trainset_species,
k = k)
# model assessment
confusionMatrix(data = predictions_kNN, reference = testset_species)
# 2. logistic regression
# Using a multinominal logit model for predictions with three response
# categories
# defining equation for algorithms
penguin.equation <- as.formula("species ~ island + bill_length_mm + bill_depth_mm +
flipper_length_mm + body_mass_g + sex + year")
# manipulating testset for predictions (omitting species)
testset_logistic <- testset %>%
select(- species)
# training logistic regression model (logit model)
logit_model1 <- multinom(penguin.equation,
data = trainset)
# computing predictions using logit model
predictions_logit <- predict(logit_model1, testset_logistic)
# model assessment
confusionMatrix(data = predictions_logit, reference = testset_species)
# 3. random forest
# manipulating testset for random forest
testset_randomforest <- testset %>%
select(- species)
# fitting random forest model
rf.model <- randomForest(penguin.equation, data = trainset)
# computing predictions
predictions_randomforest <- predict(rf.model,
newdata = testset_randomforest)
# calculating accuracy
# model assessment
confusionMatrix(data = predictions_randomforest, reference = testset_species)
# computing importance of features
importance(rf.model)
importance(rf.model, type = 1)
# Results accuracy
results_accuracy <- data.frame(algorithm = c("kNN", "logistic regression", "random forest"),
accuracy = c(accuracy_testing(vector_predictions = predictions_kNN,
vector_trueclasses = testset_species),
accuracy_testing(vector_predictions = predictions_logit,
vector_trueclasses = testset_species),
accuracy_testing(vector_predictions = predictions_randomforest,
vector_trueclasses = testset_species)))
# NOTE: path needs to be altered if function is run!
# exporting data frame as csv.
write.csv(results_accuracy,
"/Users/nicoherrig/Desktop/Data Science Projects/Penguin-classification-algorithm/results_accuracy.csv",
row.names = FALSE)
print(results_accuracy)
